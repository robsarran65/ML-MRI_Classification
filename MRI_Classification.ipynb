{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmvQxL8S9b/Z5A8M7GO9R6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robsarran65/ML-MRI_Classification/blob/main/MRI_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 1: Cell Control Flags - MASTER CONTROLS"
      ],
      "metadata": {
        "id": "KUFXr72ZsFML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸŽ›ï¸ MASTER CONTROL PANEL - Change these flags to control execution\n",
        "\n",
        "INSTALL_PACKAGES = False       # Set True if packages need installing\n",
        "DOWNLOAD_DATASET = False       # Set True to download MRI dataset\n",
        "ORGANIZE_DATA = False          # Set True to split data into train/val/test\n",
        "VISUALIZE_SAMPLES = True       # Set True to see sample MRI images\n",
        "BUILD_MODEL = True             # Set True to create the CNN model\n",
        "TRAIN_MODEL = False            # Set True to start training (takes time!)\n",
        "EVALUATE_MODEL = False         # Set True to evaluate trained model\n",
        "TEST_PREDICTIONS = False       # Set True to test individual predictions\n",
        "SAVE_MODEL = False             # Set True to save trained model\n",
        "\n",
        "# Display current settings\n",
        "print(\"ðŸŽ›ï¸ CONTROL PANEL STATUS\")\n",
        "print(\"=\"*50)\n",
        "print(f\"ðŸ“¦ Install Packages:    {'âœ… ON' if INSTALL_PACKAGES else 'â¸ï¸ OFF'}\")\n",
        "print(f\"â¬‡ï¸  Download Dataset:   {'âœ… ON' if DOWNLOAD_DATASET else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸ“ Organize Data:       {'âœ… ON' if ORGANIZE_DATA else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸ“Š Visualize Samples:   {'âœ… ON' if VISUALIZE_SAMPLES else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸ—ï¸  Build Model:        {'âœ… ON' if BUILD_MODEL else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸš€ Train Model:         {'âœ… ON' if TRAIN_MODEL else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸ“ˆ Evaluate Model:      {'âœ… ON' if EVALUATE_MODEL else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸ” Test Predictions:    {'âœ… ON' if TEST_PREDICTIONS else 'â¸ï¸ OFF'}\")\n",
        "print(f\"ðŸ’¾ Save Model:          {'âœ… ON' if SAVE_MODEL else 'â¸ï¸ OFF'}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "RnOzp7pv9DZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 2: Setup and Installation"
      ],
      "metadata": {
        "id": "Tvv9Zqry9Vhf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psHCE1vnng3d"
      },
      "outputs": [],
      "source": [
        "if INSTALL_PACKAGES:\n",
        "    print(\"ðŸ“¦ Installing required packages...\")\n",
        "\n",
        "    # Install required packages (Colab has most, but let's ensure versions)\n",
        "    !pip install -q tensorflow>=2.12.0\n",
        "    !pip install -q scikit-learn>=1.0.0\n",
        "    !pip install -q seaborn>=0.11.0\n",
        "\n",
        "    print(\"âœ… Package installation completed!\")\n",
        "else:\n",
        "    print(\"â¸ï¸ Package installation SKIPPED (assuming packages already installed)\")\n",
        "\n",
        "# Import all required libraries (always needed)\n",
        "import os\n",
        "import logging\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict, Optional, Any\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Core ML libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n",
        "print(f\"ðŸ“Š TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 3: Download and Setup MRI Dataset"
      ],
      "metadata": {
        "id": "xxPDxJSIsktj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if DOWNLOAD_DATASET:\n",
        "    print(\"â¬‡ï¸ Downloading MRI Brain Tumor Dataset...\")\n",
        "\n",
        "    # Method 1: Kaggle download (if API configured)\n",
        "    try:\n",
        "        print(\"Trying Kaggle download...\")\n",
        "        !pip install -q kaggle\n",
        "\n",
        "        # Note: You need to upload kaggle.json first!\n",
        "        # Download instructions:\n",
        "        # 1. Go to kaggle.com â†’ Account â†’ Create New API Token\n",
        "        # 2. Upload kaggle.json to Colab using file browser\n",
        "        # 3. Uncomment these lines:\n",
        "\n",
        "        # !mkdir -p ~/.kaggle\n",
        "        # !cp kaggle.json ~/.kaggle/\n",
        "        # !chmod 600 ~/.kaggle/kaggle.json\n",
        "        # !kaggle datasets download -d navoneel/brain-mri-images-for-brain-tumor-detection\n",
        "        # !unzip -q brain-mri-images-for-brain-tumor-detection.zip\n",
        "\n",
        "        print(\"â„¹ï¸ Please upload your kaggle.json file and uncomment the lines above\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Kaggle download failed: {e}\")\n",
        "\n",
        "    # Method 2: Manual upload prompt\n",
        "    print(\"\\nðŸ“ MANUAL UPLOAD OPTION:\")\n",
        "    print(\"1. Go to: https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection\")\n",
        "    print(\"2. Download the dataset ZIP file\")\n",
        "    print(\"3. Use the file browser (ðŸ“) on the left to upload the ZIP file\")\n",
        "    print(\"4. Uncomment the unzip command below:\")\n",
        "\n",
        "    # !unzip -q brain-mri-images-for-brain-tumor-detection.zip\n",
        "\n",
        "    print(\"âœ… Dataset download setup completed!\")\n",
        "else:\n",
        "    print(\"â¸ï¸ Dataset download SKIPPED\")\n",
        "    print(\"â„¹ï¸ Assuming MRI dataset is already uploaded\")\n",
        "\n",
        "# Create directory structure (always create folders)\n",
        "directories = [\n",
        "    'data/mri_dataset/train/no',\n",
        "    'data/mri_dataset/train/yes',\n",
        "    'data/mri_dataset/validation/no',\n",
        "    'data/mri_dataset/validation/yes',\n",
        "    'data/mri_dataset/test/no',\n",
        "    'data/mri_dataset/test/yes',\n",
        "    'models',\n",
        "    'results'\n",
        "]\n",
        "\n",
        "for directory in directories:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "print(\"âœ… Directory structure created!\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8zvGYBc6pfN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See the complete file structure\n",
        "# import os\n",
        "\n",
        "# def show_directory_structure(path='.', max_depth=3, current_depth=0):\n",
        "#     if current_depth > max_depth:\n",
        "#         return\n",
        "\n",
        "#     items = sorted(os.listdir(path))\n",
        "#     for item in items:\n",
        "#         item_path = os.path.join(path, item)\n",
        "#         indent = \"  \" * current_depth\n",
        "\n",
        "#         if os.path.isdir(item_path):\n",
        "#             print(f\"{indent}ðŸ“ {item}/\")\n",
        "#             try:\n",
        "#                 show_directory_structure(item_path, max_depth, current_depth + 1)\n",
        "#             except PermissionError:\n",
        "#                 print(f\"{indent}  (Permission denied)\")\n",
        "#         else:\n",
        "#             print(f\"{indent}ðŸ“„ {item}\")\n",
        "\n",
        "# print(\"ðŸ“‚ Colab Directory Structure:\")\n",
        "# show_directory_structure()"
      ],
      "metadata": {
        "id": "r2Z681_a7ig_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 4: Data Organization Helper Functions"
      ],
      "metadata": {
        "id": "s77QI2KVs_4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def organize_mri_data_colab(source_dir=\"brain_mri\", target_dir=\"data/mri_dataset\"):\n",
        "    \"\"\"\n",
        "    Organize downloaded MRI data into train/validation/test splits\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if source directory exists\n",
        "    if not os.path.exists(source_dir):\n",
        "        print(f\"âŒ Source directory '{source_dir}' not found!\")\n",
        "        print(\"Available directories:\")\n",
        "        for item in os.listdir('.'):\n",
        "            if os.path.isdir(item):\n",
        "                print(f\"  ðŸ“ {item}\")\n",
        "        return False\n",
        "\n",
        "    # Find the actual data folders\n",
        "    possible_paths = [\n",
        "        f\"{source_dir}\",\n",
        "        f\"{source_dir}/brain_mri\",\n",
        "        f\"{source_dir}/Brain MRI\",\n",
        "        \"brain_mri\",\n",
        "        \"Brain MRI\"\n",
        "    ]\n",
        "\n",
        "    data_path = None\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(f\"{path}/yes\") and os.path.exists(f\"{path}/no\"):\n",
        "            data_path = path\n",
        "            break\n",
        "\n",
        "    if not data_path:\n",
        "        print(\"âŒ Could not find 'yes' and 'no' folders in the dataset\")\n",
        "        return False\n",
        "\n",
        "    print(f\"âœ… Found data in: {data_path}\")\n",
        "\n",
        "    classes = ['no', 'yes']  # no tumor, yes tumor\n",
        "    total_moved = 0\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_dir = f\"{data_path}/{class_name}\"\n",
        "\n",
        "        # Get all images\n",
        "        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']\n",
        "        images = []\n",
        "        for ext in image_extensions:\n",
        "            images.extend(glob.glob(f\"{class_dir}/{ext}\"))\n",
        "            images.extend(glob.glob(f\"{class_dir}/{ext.upper()}\"))\n",
        "\n",
        "        if not images:\n",
        "            print(f\"âŒ No images found in {class_dir}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"ðŸ“Š Class '{class_name}': Found {len(images)} images\")\n",
        "\n",
        "        # Split data: 70% train, 20% validation, 10% test\n",
        "        train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=42)\n",
        "        val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.33, random_state=42)\n",
        "\n",
        "        # Copy files to appropriate directories\n",
        "        splits = [('train', train_imgs), ('validation', val_imgs), ('test', test_imgs)]\n",
        "\n",
        "        for split_name, img_list in splits:\n",
        "            dest_dir = f\"{target_dir}/{split_name}/{class_name}\"\n",
        "\n",
        "            for img_path in img_list:\n",
        "                filename = os.path.basename(img_path)\n",
        "                dest_path = f\"{dest_dir}/{filename}\"\n",
        "                try:\n",
        "                    shutil.copy2(img_path, dest_path)\n",
        "                    total_moved += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ Error copying {filename}: {e}\")\n",
        "\n",
        "        print(f\"âœ… Class '{class_name}': Train={len(train_imgs)}, Val={len(val_imgs)}, Test={len(test_imgs)}\")\n",
        "\n",
        "    print(f\"ðŸŽ‰ Successfully organized {total_moved} images!\")\n",
        "    return True\n",
        "\n",
        "if ORGANIZE_DATA:\n",
        "    print(\"ðŸ“ Organizing MRI dataset into train/validation/test splits...\")\n",
        "\n",
        "    # Try common source directory names\n",
        "    source_options = [\"brain_mri\", \"Brain MRI\", \"brain-mri-images-for-brain-tumor-detection\", \".\"]\n",
        "\n",
        "    organized = False\n",
        "    for source in source_options:\n",
        "        if os.path.exists(source):\n",
        "            print(f\"ðŸ” Trying source directory: {source}\")\n",
        "            organized = organize_mri_data_colab(source)\n",
        "            if organized:\n",
        "                break\n",
        "\n",
        "    if not organized:\n",
        "        print(\"âŒ Could not organize data automatically\")\n",
        "        print(\"ðŸ“ Please upload your MRI dataset and check folder names\")\n",
        "        print(\"Expected structure: [folder]/yes/ and [folder]/no/\")\n",
        "else:\n",
        "    print(\"â¸ï¸ Data organization SKIPPED\")"
      ],
      "metadata": {
        "id": "5W-siAnSrWjy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 5: MRI Binary Classifier Class"
      ],
      "metadata": {
        "id": "IHru5Ut9tWvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRIBinaryClassifier:\n",
        "    \"\"\"\n",
        "    MRI Binary Classification System optimized for Google Colab\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_name: str = \"MRI_Binary_Classifier\",\n",
        "                 img_size: Tuple[int, int] = (224, 224),\n",
        "                 batch_size: int = 16,\n",
        "                 channels: int = 1,\n",
        "                 random_seed: int = 42):\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.img_size = img_size\n",
        "        self.batch_size = batch_size\n",
        "        self.channels = channels\n",
        "        self.random_seed = random_seed\n",
        "\n",
        "        # Set random seeds for reproducibility\n",
        "        np.random.seed(random_seed)\n",
        "        tf.random.set_seed(random_seed)\n",
        "\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "        self.class_names = []\n",
        "        self.metrics = {}\n",
        "\n",
        "        # Create output directory\n",
        "        self.output_dir = Path(f\"results/{model_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\")\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"âœ… Initialized {model_name} with image size {img_size}\")\n",
        "\n",
        "    def create_data_generators(self, train_dir, validation_dir, test_dir=None):\n",
        "        \"\"\"Create data generators with medical-appropriate augmentation\"\"\"\n",
        "\n",
        "        # Conservative augmentation for medical images\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1./255,\n",
        "            rotation_range=5,          # Minimal rotation\n",
        "            zoom_range=0.05,           # Minimal zoom\n",
        "            width_shift_range=0.05,    # Small shifts\n",
        "            height_shift_range=0.05,\n",
        "            horizontal_flip=False,     # Usually not appropriate for medical\n",
        "            brightness_range=[0.95, 1.05]  # Subtle brightness changes\n",
        "        )\n",
        "\n",
        "        # No augmentation for validation/test\n",
        "        val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "        # Create generators\n",
        "        train_generator = train_datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=self.img_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='binary',\n",
        "            color_mode='grayscale' if self.channels == 1 else 'rgb',\n",
        "            shuffle=True,\n",
        "            seed=self.random_seed\n",
        "        )\n",
        "\n",
        "        validation_generator = val_test_datagen.flow_from_directory(\n",
        "            validation_dir,\n",
        "            target_size=self.img_size,\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode='binary',\n",
        "            color_mode='grayscale' if self.channels == 1 else 'rgb',\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        # Store class names\n",
        "        self.class_names = list(train_generator.class_indices.keys())\n",
        "\n",
        "        # Test generator (optional)\n",
        "        test_generator = None\n",
        "        if test_dir and os.path.exists(test_dir):\n",
        "            test_generator = val_test_datagen.flow_from_directory(\n",
        "                test_dir,\n",
        "                target_size=self.img_size,\n",
        "                batch_size=self.batch_size,\n",
        "                class_mode='binary',\n",
        "                color_mode='grayscale' if self.channels == 1 else 'rgb',\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "        print(f\"âœ… Data generators created\")\n",
        "        print(f\"   ðŸ“Š Training samples: {train_generator.samples}\")\n",
        "        print(f\"   ðŸ“Š Validation samples: {validation_generator.samples}\")\n",
        "        if test_generator:\n",
        "            print(f\"   ðŸ“Š Test samples: {test_generator.samples}\")\n",
        "        print(f\"   ðŸ·ï¸ Classes: {self.class_names}\")\n",
        "\n",
        "        return train_generator, validation_generator, test_generator\n",
        "\n",
        "    def build_model(self, architecture=\"lightweight\"):\n",
        "        \"\"\"Build CNN model\"\"\"\n",
        "\n",
        "        input_shape = (*self.img_size, self.channels)\n",
        "\n",
        "        if architecture == \"lightweight\":\n",
        "            model = keras.Sequential([\n",
        "                layers.Input(shape=input_shape),\n",
        "\n",
        "                # Block 1\n",
        "                layers.Conv2D(16, (3, 3), activation='relu'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.MaxPooling2D(2, 2),\n",
        "                layers.Dropout(0.25),\n",
        "\n",
        "                # Block 2\n",
        "                layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.MaxPooling2D(2, 2),\n",
        "                layers.Dropout(0.25),\n",
        "\n",
        "                # Block 3\n",
        "                layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.MaxPooling2D(2, 2),\n",
        "                layers.Dropout(0.5),\n",
        "\n",
        "                # Classifier\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "                layers.Dense(64, activation='relu'),\n",
        "                layers.Dropout(0.5),\n",
        "                layers.Dense(1, activation='sigmoid', name='predictions')\n",
        "            ])\n",
        "\n",
        "        elif architecture == \"standard\":\n",
        "            model = keras.Sequential([\n",
        "                layers.Input(shape=input_shape),\n",
        "\n",
        "                # Block 1\n",
        "                layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.MaxPooling2D(2, 2),\n",
        "                layers.Dropout(0.25),\n",
        "\n",
        "                # Block 2\n",
        "                layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.MaxPooling2D(2, 2),\n",
        "                layers.Dropout(0.5),\n",
        "\n",
        "                # Block 3\n",
        "                layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.MaxPooling2D(2, 2),\n",
        "                layers.Dropout(0.5),\n",
        "\n",
        "                # Classifier\n",
        "                layers.GlobalAveragePooling2D(),\n",
        "                layers.Dense(256, activation='relu'),\n",
        "                layers.Dropout(0.5),\n",
        "                layers.Dense(1, activation='sigmoid', name='predictions')\n",
        "            ])\n",
        "\n",
        "        # Compile model\n",
        "        model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', 'precision', 'recall']\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        print(f\"âœ… Model built with {architecture} architecture\")\n",
        "        return model\n",
        "\n",
        "    def train_model(self, train_generator, validation_generator, epochs=20, show_live_progress=True):\n",
        "        \"\"\"Train the model with visible epoch progress like horses vs humans\"\"\"\n",
        "\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model must be built before training\")\n",
        "\n",
        "        print(f\"ðŸš€ Starting training for {epochs} epochs...\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if show_live_progress:\n",
        "            # Minimal callbacks for live progress (like horses vs humans)\n",
        "            callbacks_list = [\n",
        "                callbacks.EarlyStopping(\n",
        "                    monitor='val_loss',\n",
        "                    patience=7,  # More patience to see more epochs\n",
        "                    restore_best_weights=True,\n",
        "                    verbose=1\n",
        "                )\n",
        "            ]\n",
        "\n",
        "            # Train with full verbose output (like horses vs humans)\n",
        "            self.history = self.model.fit(\n",
        "                train_generator,\n",
        "                epochs=epochs,\n",
        "                validation_data=validation_generator,\n",
        "                callbacks=callbacks_list,\n",
        "                verbose=1,  # This shows the live epoch progress\n",
        "                steps_per_epoch=len(train_generator),\n",
        "                validation_steps=len(validation_generator)\n",
        "            )\n",
        "        else:\n",
        "            # Professional mode with all callbacks\n",
        "            callbacks_list = [\n",
        "                callbacks.EarlyStopping(\n",
        "                    monitor='val_loss',\n",
        "                    patience=5,\n",
        "                    restore_best_weights=True,\n",
        "                    verbose=1\n",
        "                ),\n",
        "                callbacks.ReduceLROnPlateau(\n",
        "                    monitor='val_loss',\n",
        "                    factor=0.5,\n",
        "                    patience=3,\n",
        "                    min_lr=1e-7,\n",
        "                    verbose=1\n",
        "                )\n",
        "            ]\n",
        "\n",
        "            self.history = self.model.fit(\n",
        "                train_generator,\n",
        "                epochs=epochs,\n",
        "                validation_data=validation_generator,\n",
        "                callbacks=callbacks_list,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "        print(\"=\"*60)\n",
        "        print(\"âœ… Training completed!\")\n",
        "\n",
        "        # Show final epoch summary (like horses vs humans)\n",
        "        if self.history and self.history.history:\n",
        "            final_epoch = len(self.history.history['accuracy'])\n",
        "            final_acc = self.history.history['accuracy'][-1]\n",
        "            final_val_acc = self.history.history['val_accuracy'][-1]\n",
        "            final_loss = self.history.history['loss'][-1]\n",
        "            final_val_loss = self.history.history['val_loss'][-1]\n",
        "\n",
        "            print(f\"\\nðŸŽ¯ FINAL RESULTS (Epoch {final_epoch}):\")\n",
        "            print(f\"   Training Accuracy:   {final_acc:.4f}\")\n",
        "            print(f\"   Validation Accuracy: {final_val_acc:.4f}\")\n",
        "            print(f\"   Training Loss:       {final_loss:.4f}\")\n",
        "            print(f\"   Validation Loss:     {final_val_loss:.4f}\")\n",
        "\n",
        "        return self.history\n",
        "\n",
        "    def evaluate_model(self, test_generator):\n",
        "        \"\"\"Comprehensive model evaluation\"\"\"\n",
        "\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model must be trained before evaluation\")\n",
        "\n",
        "        print(\"ðŸ“Š Evaluating model...\")\n",
        "\n",
        "        # Get predictions\n",
        "        predictions = self.model.predict(test_generator, verbose=1)\n",
        "        y_pred_binary = (predictions > 0.5).astype(int)\n",
        "        y_true = test_generator.classes\n",
        "\n",
        "        # Calculate metrics\n",
        "        test_loss, test_accuracy, test_precision, test_recall = self.model.evaluate(\n",
        "            test_generator, verbose=1\n",
        "        )\n",
        "\n",
        "        f1_score = 2 * (test_precision * test_recall) / (test_precision + test_recall + 1e-7)\n",
        "\n",
        "        try:\n",
        "            auc_score = roc_auc_score(y_true, predictions)\n",
        "        except:\n",
        "            auc_score = 0.0\n",
        "\n",
        "        self.metrics = {\n",
        "            'test_loss': float(test_loss),\n",
        "            'test_accuracy': float(test_accuracy),\n",
        "            'test_precision': float(test_precision),\n",
        "            'test_recall': float(test_recall),\n",
        "            'test_f1_score': float(f1_score),\n",
        "            'test_auc': float(auc_score)\n",
        "        }\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\nðŸŽ¯ EVALUATION RESULTS:\")\n",
        "        print(\"=\"*40)\n",
        "        print(f\"   ðŸ“Š Accuracy:  {test_accuracy:.2%}\")\n",
        "        print(f\"   ðŸ“Š Precision: {test_precision:.2%}\")\n",
        "        print(f\"   ðŸ“Š Recall:    {test_recall:.2%}\")\n",
        "        print(f\"   ðŸ“Š F1-Score:  {f1_score:.2%}\")\n",
        "        print(f\"   ðŸ“Š AUC:       {auc_score:.3f}\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred_binary)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d',\n",
        "                   xticklabels=self.class_names,\n",
        "                   yticklabels=self.class_names,\n",
        "                   cmap='Blues')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.show()\n",
        "\n",
        "        return self.metrics\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        \"\"\"Plot training progress\"\"\"\n",
        "\n",
        "        if self.history is None:\n",
        "            print(\"âŒ No training history available\")\n",
        "            return\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Accuracy plot\n",
        "        axes[0].plot(self.history.history['accuracy'], label='Training Accuracy', linewidth=2)\n",
        "        axes[0].plot(self.history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
        "        axes[0].set_title('Model Accuracy')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Accuracy')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        axes[1].plot(self.history.history['loss'], label='Training Loss', linewidth=2)\n",
        "        axes[1].plot(self.history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "        axes[1].set_title('Model Loss')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Loss')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def predict_single_image(self, image_path):\n",
        "        \"\"\"Predict on single image\"\"\"\n",
        "\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model must be loaded before prediction\")\n",
        "\n",
        "        # Load and preprocess image\n",
        "        img = keras.preprocessing.image.load_img(\n",
        "            image_path,\n",
        "            target_size=self.img_size,\n",
        "            color_mode='grayscale' if self.channels == 1 else 'rgb'\n",
        "        )\n",
        "\n",
        "        img_array = keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = img_array / 255.0\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(img_array, verbose=0)[0][0]\n",
        "        predicted_class = int(prediction > 0.5)\n",
        "        confidence = prediction if predicted_class == 1 else 1 - prediction\n",
        "\n",
        "        return {\n",
        "            'predicted_class': predicted_class,\n",
        "            'class_name': self.class_names[predicted_class] if self.class_names else str(predicted_class),\n",
        "            'confidence': float(confidence),\n",
        "            'raw_prediction': float(prediction)\n",
        "        }\n",
        "\n",
        "print(\"âœ… MRIBinaryClassifier class loaded successfully!\")"
      ],
      "metadata": {
        "id": "HwgOAQmItZ68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 6: Data Visualization"
      ],
      "metadata": {
        "id": "6Mrrv4Hltncb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_mri_samples(data_dir=\"data/mri_dataset/train\", num_samples=8):\n",
        "    \"\"\"Visualize sample MRI images\"\"\"\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"âŒ Directory {data_dir} not found!\")\n",
        "        return False\n",
        "\n",
        "    # Check if directory has data\n",
        "    subdirs = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    if not subdirs:\n",
        "        print(f\"âŒ No subdirectories found in {data_dir}\")\n",
        "        return False\n",
        "\n",
        "    # Create data generator for visualization\n",
        "    datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    try:\n",
        "        generator = datagen.flow_from_directory(\n",
        "            data_dir,\n",
        "            target_size=(224, 224),\n",
        "            batch_size=num_samples,\n",
        "            class_mode='binary',\n",
        "            color_mode='grayscale',\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        # Get a batch of images\n",
        "        batch = next(generator)\n",
        "        images, labels = batch[0], batch[1]\n",
        "        class_names = list(generator.class_indices.keys())\n",
        "\n",
        "        # Display images\n",
        "        plt.figure(figsize=(15, 8))\n",
        "        for i in range(min(num_samples, len(images))):\n",
        "            plt.subplot(2, 4, i+1)\n",
        "            plt.imshow(images[i].reshape(224, 224), cmap='gray')\n",
        "            class_name = class_names[int(labels[i])]\n",
        "            title = \"Normal Brain\" if class_name == \"no\" else \"Tumor Detected\"\n",
        "            color = 'green' if class_name == \"no\" else 'red'\n",
        "            plt.title(title, color=color, fontsize=12, fontweight='bold')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.suptitle('ðŸ§  MRI Brain Scan Samples', fontsize=16, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"âœ… Displayed {min(num_samples, len(images))} sample images\")\n",
        "        print(f\"ðŸ·ï¸ Classes found: {class_names}\")\n",
        "        print(f\"ðŸ“Š Dataset stats:\")\n",
        "        for class_name in class_names:\n",
        "            class_dir = os.path.join(data_dir, class_name)\n",
        "            if os.path.exists(class_dir):\n",
        "                count = len([f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n",
        "                print(f\"   {class_name}: {count} images\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error visualizing data: {e}\")\n",
        "        return False\n",
        "\n",
        "if VISUALIZE_SAMPLES:\n",
        "    print(\"ðŸ“Š Visualizing MRI sample images...\")\n",
        "\n",
        "    # Try to visualize training data\n",
        "    visualization_success = visualize_mri_samples(\"data/mri_dataset/train\")\n",
        "\n",
        "    if not visualization_success:\n",
        "        print(\"âš ï¸ Could not visualize training data\")\n",
        "        print(\"â„¹ï¸ Please check that your data is organized in the correct folders\")\n",
        "\n",
        "        # Show current directory structure\n",
        "        print(\"\\nðŸ“ Current directory structure:\")\n",
        "        for root, dirs, files in os.walk(\"data\"):\n",
        "            level = root.replace(\"data\", \"\").count(os.sep)\n",
        "            indent = \" \" * 2 * level\n",
        "            print(f\"{indent}{os.path.basename(root)}/\")\n",
        "            subindent = \" \" * 2 * (level + 1)\n",
        "            for file in files[:3]:  # Show first 3 files\n",
        "                print(f\"{subindent}{file}\")\n",
        "            if len(files) > 3:\n",
        "                print(f\"{subindent}... and {len(files)-3} more files\")\n",
        "else:\n",
        "    print(\"â¸ï¸ Data visualization SKIPPED\")"
      ],
      "metadata": {
        "id": "d7vJFTD6tobD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 7: Model Building"
      ],
      "metadata": {
        "id": "1Z1Yamb-tuXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables to store our model and data\n",
        "classifier = None\n",
        "train_gen = None\n",
        "val_gen = None\n",
        "test_gen = None\n",
        "\n",
        "if BUILD_MODEL:\n",
        "    print(\"ðŸ—ï¸ Building MRI Classification Model...\")\n",
        "\n",
        "    # Initialize classifier\n",
        "    classifier = MRIBinaryClassifier(\n",
        "        model_name=\"Colab_Brain_Tumor_Detector\",\n",
        "        img_size=(224, 224),\n",
        "        channels=1,           # Grayscale MRI images\n",
        "        batch_size=16\n",
        "    )\n",
        "\n",
        "    # Setup data paths\n",
        "    train_dir = \"data/mri_dataset/train\"\n",
        "    val_dir = \"data/mri_dataset/validation\"\n",
        "    test_dir = \"data/mri_dataset/test\"\n",
        "\n",
        "    # Check if data exists\n",
        "    if not os.path.exists(train_dir):\n",
        "        print(f\"âŒ Training data not found at: {train_dir}\")\n",
        "        print(\"â„¹ï¸ Please organize your data first by setting ORGANIZE_DATA = True\")\n",
        "    else:\n",
        "        try:\n",
        "            # Create data generators\n",
        "            train_gen, val_gen, test_gen = classifier.create_data_generators(\n",
        "                train_dir, val_dir, test_dir\n",
        "            )\n",
        "\n",
        "            # Build the model\n",
        "            classifier.build_model(architecture=\"lightweight\")  # Start with lightweight\n",
        "\n",
        "            # Show model summary\n",
        "            print(\"\\nðŸ“‹ MODEL ARCHITECTURE:\")\n",
        "            classifier.model.summary()\n",
        "\n",
        "            print(\"\\nâœ… Model built successfully!\")\n",
        "            print(\"ðŸŽ¯ Ready for training!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error building model: {e}\")\n",
        "            classifier = None\n",
        "else:\n",
        "    print(\"â¸ï¸ Model building SKIPPED\")"
      ],
      "metadata": {
        "id": "eC4qFUd1tyLK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " CELL 8: Model Training"
      ],
      "metadata": {
        "id": "OfG8uO6it8ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if TRAIN_MODEL:\n",
        "    if classifier is None or train_gen is None:\n",
        "        print(\"âŒ Cannot train: Model not built or data not loaded\")\n",
        "        print(\"â„¹ï¸ Please set BUILD_MODEL = True first\")\n",
        "    else:\n",
        "        print(\"ðŸš€ Starting MRI Model Training...\")\n",
        "        print(\"ðŸ“º You should see live epoch progress below (like horses vs humans):\")\n",
        "        print(\"â° This may take several minutes...\")\n",
        "        print()\n",
        "\n",
        "        # Train the model with live progress display\n",
        "        history = classifier.train_model(\n",
        "            train_gen,\n",
        "            val_gen,\n",
        "            epochs=15,           # Start with fewer epochs for testing\n",
        "            show_live_progress=True  # This enables horses vs humans style output\n",
        "        )\n",
        "\n",
        "        # Plot training history\n",
        "        print(\"\\nðŸ“ˆ Training Progress Visualization:\")\n",
        "        classifier.plot_training_history()\n",
        "\n",
        "        print(\"âœ… Training completed!\")\n",
        "\n",
        "        # Show training summary like horses vs humans\n",
        "        if history and history.history:\n",
        "            print(f\"\\nðŸ“Š TRAINING SUMMARY:\")\n",
        "            print(\"=\"*40)\n",
        "            epochs_completed = len(history.history['accuracy'])\n",
        "            best_val_acc = max(history.history['val_accuracy'])\n",
        "            best_epoch = history.history['val_accuracy'].index(best_val_acc) + 1\n",
        "\n",
        "            print(f\"   Epochs completed: {epochs_completed}\")\n",
        "            print(f\"   Best validation accuracy: {best_val_acc:.4f} (epoch {best_epoch})\")\n",
        "            print(f\"   Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "            print(f\"   Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "            print(\"=\"*40)\n",
        "else:\n",
        "    print(\"â¸ï¸ Model training SKIPPED\")\n",
        "    print(\"â„¹ï¸ Set TRAIN_MODEL = True to start training\")\n",
        "    print(\"ðŸ’¡ When you train, you'll see live epoch progress like this:\")\n",
        "    print(\"   Epoch 1/15\")\n",
        "    print(\"   8/8 [==============================] - 45s - loss: 0.6821 - accuracy: 0.5484 - val_loss: 0.6234 - val_accuracy: 0.6667\")\n",
        "    print(\"   Epoch 2/15\")\n",
        "    print(\"   8/8 [==============================] - 12s - loss: 0.5234 - accuracy: 0.7258 - val_loss: 0.4987 - val_accuracy: 0.7500\")\n",
        "    print(\"   ...\")"
      ],
      "metadata": {
        "id": "sntY8PUXt-Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 9: Model Evaluation"
      ],
      "metadata": {
        "id": "ZbUVpJwV_6rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if EVALUATE_MODEL:\n",
        "    if classifier is None or classifier.model is None:\n",
        "        print(\"âŒ Cannot evaluate: No trained model available\")\n",
        "        print(\"â„¹ï¸ Please train the model first by setting TRAIN_MODEL = True\")\n",
        "    elif test_gen is None or test_gen.samples == 0:\n",
        "        print(\"âŒ Cannot evaluate: No test data available\")\n",
        "        print(\"â„¹ï¸ Please check your test data organization\")\n",
        "    else:\n",
        "        print(\"ðŸ“Š Evaluating trained model on test data...\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        evaluation_results = classifier.evaluate_model(test_gen)\n",
        "\n",
        "        # Additional analysis\n",
        "        print(\"\\nðŸ” DETAILED ANALYSIS:\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Medical interpretation\n",
        "        accuracy = evaluation_results['test_accuracy']\n",
        "        precision = evaluation_results['test_precision']\n",
        "        recall = evaluation_results['test_recall']\n",
        "\n",
        "        if accuracy > 0.90:\n",
        "            print(\"ðŸŸ¢ EXCELLENT: Very high accuracy model\")\n",
        "        elif accuracy > 0.80:\n",
        "            print(\"ðŸŸ¡ GOOD: Acceptable accuracy for medical screening\")\n",
        "        elif accuracy > 0.70:\n",
        "            print(\"ðŸŸ  MODERATE: May need improvement for clinical use\")\n",
        "        else:\n",
        "            print(\"ðŸ”´ POOR: Requires significant improvement\")\n",
        "\n",
        "        print(f\"ðŸ“Š Precision focus: {precision:.1%} of tumor predictions are correct\")\n",
        "        print(f\"ðŸ“Š Recall focus: {recall:.1%} of actual tumors are detected\")\n",
        "        print(\"=\"*50)\n",
        "else:\n",
        "    print(\"â¸ï¸ Model evaluation SKIPPED\")\n",
        "    print(\"â„¹ï¸ Set EVALUATE_MODEL = True after training to evaluate performance\")"
      ],
      "metadata": {
        "id": "28bGK4m6_7xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 10: Individual Image Predictions"
      ],
      "metadata": {
        "id": "rZvCOzpLAkc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_individual_predictions():\n",
        "    \"\"\"Test predictions on individual MRI scans\"\"\"\n",
        "\n",
        "    if classifier is None or classifier.model is None:\n",
        "        print(\"âŒ No trained model available for predictions\")\n",
        "        return False\n",
        "\n",
        "    # Find test images\n",
        "    test_dirs = [\"data/mri_dataset/test/no\", \"data/mri_dataset/test/yes\"]\n",
        "    test_images = []\n",
        "\n",
        "    for test_dir in test_dirs:\n",
        "        if os.path.exists(test_dir):\n",
        "            images = glob.glob(f\"{test_dir}/*.jpg\") + glob.glob(f\"{test_dir}/*.png\") + glob.glob(f\"{test_dir}/*.jpeg\")\n",
        "            test_images.extend(images[:3])  # Take 3 from each class\n",
        "\n",
        "    if not test_images:\n",
        "        print(\"âŒ No test images found!\")\n",
        "        print(\"â„¹ï¸ Please check your test data organization\")\n",
        "        return False\n",
        "\n",
        "    print(f\"ðŸ” Testing predictions on {len(test_images)} individual scans...\")\n",
        "\n",
        "    # Make predictions and visualize\n",
        "    plt.figure(figsize=(18, 12))\n",
        "\n",
        "    for i, img_path in enumerate(test_images[:6]):\n",
        "        try:\n",
        "            # Make prediction\n",
        "            result = classifier.predict_single_image(img_path)\n",
        "\n",
        "            # Load image for display\n",
        "            img = plt.imread(img_path)\n",
        "\n",
        "            plt.subplot(2, 3, i+1)\n",
        "            plt.imshow(img, cmap='gray')\n",
        "\n",
        "            # Determine true class from folder name\n",
        "            true_class = \"Tumor\" if \"/yes/\" in img_path else \"Normal\"\n",
        "            pred_class = \"Tumor\" if result['predicted_class'] == 1 else \"Normal\"\n",
        "            confidence = result['confidence']\n",
        "\n",
        "            # Color coding: green for correct, red for incorrect\n",
        "            is_correct = true_class == pred_class\n",
        "            color = 'green' if is_correct else 'red'\n",
        "\n",
        "            # Create detailed title\n",
        "            title = f\"True: {true_class}\\nPred: {pred_class} ({confidence:.1%})\"\n",
        "            if is_correct:\n",
        "                title += \"\\nâœ… CORRECT\"\n",
        "            else:\n",
        "                title += \"\\nâŒ INCORRECT\"\n",
        "\n",
        "            plt.title(title, color=color, fontsize=10, fontweight='bold')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Print detailed results\n",
        "            filename = os.path.basename(img_path)\n",
        "            status = \"âœ… CORRECT\" if is_correct else \"âŒ INCORRECT\"\n",
        "            print(f\"ðŸ“ {filename}: {pred_class} ({confidence:.1%}) {status}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Error processing {img_path}: {e}\")\n",
        "\n",
        "    plt.suptitle('ðŸ§  Individual MRI Scan Predictions', fontsize=16, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return True\n",
        "\n",
        "if TEST_PREDICTIONS:\n",
        "    if classifier is None or classifier.model is None:\n",
        "        print(\"âŒ Cannot test predictions: No trained model available\")\n",
        "        print(\"â„¹ï¸ Please train the model first by setting TRAIN_MODEL = True\")\n",
        "    else:\n",
        "        print(\"ðŸ” Testing individual image predictions...\")\n",
        "        prediction_success = test_individual_predictions()\n",
        "\n",
        "        if prediction_success:\n",
        "            print(\"\\nðŸŽ¯ PREDICTION ANALYSIS COMPLETE!\")\n",
        "            print(\"=\"*50)\n",
        "            print(\"ðŸ’¡ Interpretation Guide:\")\n",
        "            print(\"   ðŸŸ¢ Green borders: Correct predictions\")\n",
        "            print(\"   ðŸ”´ Red borders: Incorrect predictions\")\n",
        "            print(\"   ðŸ“Š Confidence >80%: High confidence\")\n",
        "            print(\"   ðŸ“Š Confidence 60-80%: Moderate confidence\")\n",
        "            print(\"   ðŸ“Š Confidence <60%: Low confidence\")\n",
        "            print(\"=\"*50)\n",
        "        else:\n",
        "            print(\"âŒ Could not test predictions\")\n",
        "else:\n",
        "    print(\"â¸ï¸ Individual predictions SKIPPED\")\n",
        "    print(\"â„¹ï¸ Set TEST_PREDICTIONS = True after training to test on individual images\")"
      ],
      "metadata": {
        "id": "xJgVIs2KAlq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 11: Save Trained Model"
      ],
      "metadata": {
        "id": "VJHQ5HFCAteG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if SAVE_MODEL:\n",
        "    if classifier is None or classifier.model is None:\n",
        "        print(\"âŒ Cannot save: No trained model available\")\n",
        "        print(\"â„¹ï¸ Please train the model first by setting TRAIN_MODEL = True\")\n",
        "    else:\n",
        "        print(\"ðŸ’¾ Saving trained model...\")\n",
        "\n",
        "        # Create models directory if it doesn't exist\n",
        "        os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "        # Save model with timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        model_filename = f\"colab_brain_tumor_detector_{timestamp}.h5\"\n",
        "        model_path = f\"models/{model_filename}\"\n",
        "\n",
        "        try:\n",
        "            # Save the model\n",
        "            classifier.model.save(model_path)\n",
        "\n",
        "            # Save metadata\n",
        "            metadata = {\n",
        "                'model_name': classifier.model_name,\n",
        "                'creation_date': datetime.now().isoformat(),\n",
        "                'image_size': classifier.img_size,\n",
        "                'channels': classifier.channels,\n",
        "                'class_names': classifier.class_names,\n",
        "                'metrics': classifier.metrics if hasattr(classifier, 'metrics') else {},\n",
        "                'tensorflow_version': tf.__version__\n",
        "            }\n",
        "\n",
        "            metadata_path = model_path.replace('.h5', '_metadata.json')\n",
        "            with open(metadata_path, 'w') as f:\n",
        "                json.dump(metadata, f, indent=2)\n",
        "\n",
        "            print(f\"âœ… Model saved successfully!\")\n",
        "            print(f\"   ðŸ“ Model file: {model_path}\")\n",
        "            print(f\"   ðŸ“‹ Metadata: {metadata_path}\")\n",
        "\n",
        "            # Show how to load the model later\n",
        "            print(\"\\nðŸ“– TO LOAD THIS MODEL LATER:\")\n",
        "            print(\"=\"*50)\n",
        "            print(\"# Create new classifier instance\")\n",
        "            print(\"new_classifier = MRIBinaryClassifier()\")\n",
        "            print(f\"# Load the saved model\")\n",
        "            print(f\"new_classifier.model = keras.models.load_model('{model_path}')\")\n",
        "            print(\"# Set class names manually\")\n",
        "            print(\"new_classifier.class_names = ['no', 'yes']\")\n",
        "            print(\"# Now ready for predictions!\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error saving model: {e}\")\n",
        "else:\n",
        "    print(\"â¸ï¸ Model saving SKIPPED\")\n",
        "    print(\"â„¹ï¸ Set SAVE_MODEL = True after training to save your model\")"
      ],
      "metadata": {
        "id": "ZpOy8Qu8Aw2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 12: Load Existing Model (For Testing)"
      ],
      "metadata": {
        "id": "B6R3CqqkA1qG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_existing_model(model_path):\n",
        "    \"\"\"Load a previously saved model\"\"\"\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"âŒ Model file not found: {model_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Create new classifier instance\n",
        "        loaded_classifier = MRIBinaryClassifier(\n",
        "            model_name=\"Loaded_Model\",\n",
        "            img_size=(224, 224),\n",
        "            channels=1\n",
        "        )\n",
        "\n",
        "        # Load the model\n",
        "        loaded_classifier.model = keras.models.load_model(model_path)\n",
        "        loaded_classifier.class_names = ['no', 'yes']  # Set class names\n",
        "\n",
        "        # Load metadata if available\n",
        "        metadata_path = model_path.replace('.h5', '_metadata.json')\n",
        "        if os.path.exists(metadata_path):\n",
        "            with open(metadata_path, 'r') as f:\n",
        "                metadata = json.load(f)\n",
        "                print(\"ðŸ“‹ Model Metadata:\")\n",
        "                for key, value in metadata.items():\n",
        "                    if key != 'metrics':  # Skip detailed metrics\n",
        "                        print(f\"   {key}: {value}\")\n",
        "\n",
        "        print(f\"âœ… Model loaded successfully from: {model_path}\")\n",
        "        return loaded_classifier\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error loading model: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example of how to load a saved model\n",
        "print(\"ðŸ’¾ LOAD EXISTING MODEL EXAMPLE:\")\n",
        "print(\"=\"*50)\n",
        "print(\"# To load a previously saved model, use:\")\n",
        "print(\"# loaded_classifier = load_existing_model('models/your_model.h5')\")\n",
        "print(\"# Then you can make predictions:\")\n",
        "print(\"# result = loaded_classifier.predict_single_image('path/to/mri_scan.jpg')\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "id": "_t2aHKR9A41m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 13: Complete Workflow Summary"
      ],
      "metadata": {
        "id": "0CtUfbvvA9vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸŽ‰ GOOGLE COLAB MRI CLASSIFICATION WORKFLOW COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"ðŸ“‹ WORKFLOW SUMMARY:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Check what was accomplished\n",
        "completed_steps = []\n",
        "skipped_steps = []\n",
        "\n",
        "if INSTALL_PACKAGES:\n",
        "    completed_steps.append(\"âœ… Package Installation\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Package Installation\")\n",
        "\n",
        "if DOWNLOAD_DATASET:\n",
        "    completed_steps.append(\"âœ… Dataset Download\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Dataset Download\")\n",
        "\n",
        "if ORGANIZE_DATA:\n",
        "    completed_steps.append(\"âœ… Data Organization\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Data Organization\")\n",
        "\n",
        "if VISUALIZE_SAMPLES:\n",
        "    completed_steps.append(\"âœ… Data Visualization\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Data Visualization\")\n",
        "\n",
        "if BUILD_MODEL:\n",
        "    completed_steps.append(\"âœ… Model Building\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Model Building\")\n",
        "\n",
        "if TRAIN_MODEL:\n",
        "    completed_steps.append(\"âœ… Model Training\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Model Training\")\n",
        "\n",
        "if EVALUATE_MODEL:\n",
        "    completed_steps.append(\"âœ… Model Evaluation\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Model Evaluation\")\n",
        "\n",
        "if TEST_PREDICTIONS:\n",
        "    completed_steps.append(\"âœ… Individual Predictions\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Individual Predictions\")\n",
        "\n",
        "if SAVE_MODEL:\n",
        "    completed_steps.append(\"âœ… Model Saving\")\n",
        "else:\n",
        "    skipped_steps.append(\"â¸ï¸ Model Saving\")\n",
        "\n",
        "print(\"ðŸŸ¢ COMPLETED STEPS:\")\n",
        "for step in completed_steps:\n",
        "    print(f\"   {step}\")\n",
        "\n",
        "print(\"\\nðŸŸ¡ SKIPPED STEPS:\")\n",
        "for step in skipped_steps:\n",
        "    print(f\"   {step}\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ NEXT STEPS RECOMMENDATIONS:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if not DOWNLOAD_DATASET and not ORGANIZE_DATA:\n",
        "    print(\"1. ðŸ“ Upload your MRI dataset and organize it\")\n",
        "    print(\"   - Set DOWNLOAD_DATASET = True or ORGANIZE_DATA = True\")\n",
        "\n",
        "if not VISUALIZE_SAMPLES:\n",
        "    print(\"2. ðŸ“Š Visualize your data to understand it\")\n",
        "    print(\"   - Set VISUALIZE_SAMPLES = True\")\n",
        "\n",
        "if not BUILD_MODEL:\n",
        "    print(\"3. ðŸ—ï¸ Build the CNN model\")\n",
        "    print(\"   - Set BUILD_MODEL = True\")\n",
        "\n",
        "if not TRAIN_MODEL:\n",
        "    print(\"4. ðŸš€ Train your model\")\n",
        "    print(\"   - Set TRAIN_MODEL = True (this takes the most time)\")\n",
        "\n",
        "if not EVALUATE_MODEL and TRAIN_MODEL:\n",
        "    print(\"5. ðŸ“Š Evaluate model performance\")\n",
        "    print(\"   - Set EVALUATE_MODEL = True\")\n",
        "\n",
        "if not TEST_PREDICTIONS and TRAIN_MODEL:\n",
        "    print(\"6. ðŸ” Test individual predictions\")\n",
        "    print(\"   - Set TEST_PREDICTIONS = True\")\n",
        "\n",
        "if not SAVE_MODEL and TRAIN_MODEL:\n",
        "    print(\"7. ðŸ’¾ Save your trained model\")\n",
        "    print(\"   - Set SAVE_MODEL = True\")\n",
        "\n",
        "print(\"\\nðŸ’¡ TIPS FOR SUCCESS:\")\n",
        "print(\"=\"*60)\n",
        "print(\"â€¢ Start with small datasets and lightweight models\")\n",
        "print(\"â€¢ Enable GPU runtime: Runtime â†’ Change runtime type â†’ GPU\")\n",
        "print(\"â€¢ Monitor training progress and stop early if overfitting\")\n",
        "print(\"â€¢ Save your models regularly to avoid losing progress\")\n",
        "print(\"â€¢ Test different architectures: 'lightweight', 'standard', 'deep'\")\n",
        "print(\"â€¢ Use Google Drive for large datasets and model storage\")\n",
        "\n",
        "print(\"\\nðŸ”„ TO RESTART OR MODIFY:\")\n",
        "print(\"=\"*60)\n",
        "print(\"â€¢ Go back to Cell 1 (Control Flags)\")\n",
        "print(\"â€¢ Change the flags for steps you want to run\")\n",
        "print(\"â€¢ Re-run the cells in order\")\n",
        "print(\"â€¢ Each cell checks its flag before executing\")\n",
        "\n",
        "print(\"\\nâœ¨ CONGRATULATIONS!\")\n",
        "print(\"You now have a professional MRI classification system!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "zQXJhGVqBDW-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}